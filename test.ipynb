{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Lambda, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.regularizers import l2\n",
    "K.set_image_data_format('channels_last')\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=np.float32):\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "def initialize_bias(shape, dtype=np.float32):\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "def get_siamese_model():\n",
    "    left_input = Input(shape=(38,))\n",
    "    right_input = Input(shape=(38,))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu',\n",
    "                    input_shape=(38,),\n",
    "                    kernel_regularizer=l2(1e-3),\n",
    "                    kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    kernel_regularizer=l2(1e-3),\n",
    "                    kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    kernel_regularizer=l2(1e-3),\n",
    "                    kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    prediction = Dense(1,activation='sigmoid', bias_initializer=initialize_bias)(L1_distance)\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(data, support_data):\n",
    "    input1=[]\n",
    "    input2=[]\n",
    "    for i in range(0, len(data)):\n",
    "        for j in range(0, len(support_data)):\n",
    "            input1.append(data[i])\n",
    "        for j in support_data:\n",
    "            input2.append(j[0:38])\n",
    "\n",
    "    input1=np.array(input1).astype(np.float32)\n",
    "    input2=np.array(input2).astype(np.float32)\n",
    "\n",
    "    data_size=len(data)\n",
    "    support_data_size=len(support_data)\n",
    "    return input1, input2, data_size, support_data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, 3, 4 WAY LEARNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=pd.read_csv('data/data_by_label_test_unseen/mscan.csv', 'r', delimiter=',').values\n",
    "a=pd.read_csv('data/data_by_label_test_unseen/apache2.csv', 'r', delimiter=',').values\n",
    "p=pd.read_csv('data/data_by_label_test_unseen/processtable.csv', 'r', delimiter=',').values\n",
    "s=pd.read_csv('data/data_by_label_test_unseen/snmpguess.csv', 'r', delimiter=',').values\n",
    "def predict_acc(*args):\n",
    "    model=get_siamese_model()\n",
    "    model=load_model('model/test1.h5',custom_objects={'initialize_weights':initialize_weights, 'initialize_bias':initialize_bias})\n",
    "    data=args[0]\n",
    "    for i in range(1, len(args)):\n",
    "        data=np.concatenate((data, args[i]), axis=0)\n",
    "    feature=[]\n",
    "    label=[]\n",
    "    for i in data:\n",
    "        feature.append(i[0:38])\n",
    "        label.append(i[38])\n",
    "    \n",
    "    support_datas=pd.read_csv('data/support_data/support_data_one_shot.csv', 'r', delimiter=',').values\n",
    "    support_data=[]\n",
    "    label_array=[]\n",
    "    for i in support_datas:\n",
    "        if i[38] in label:\n",
    "            support_data.append(i)\n",
    "            label_array.append(i[38])\n",
    "    \n",
    "    feature=np.reshape(feature, (len(feature), 38)).astype(np.float32)\n",
    "    input1, input2, data_size, support_data_size=make_input(feature, support_data)\n",
    "    \n",
    "    prediction=model.predict([input1, input2])\n",
    "    prediction=prediction.reshape(data_size, support_data_size)\n",
    "    \n",
    "    prediction_best=[]\n",
    "    for i in prediction:\n",
    "        prediction_best.append(np.where(min(i)==i)[0][0])\n",
    "    \n",
    "    label_num=[]\n",
    "    for i in label:\n",
    "        for j in label_array:\n",
    "            if i==j:\n",
    "                label_num.append(label_array.index(i))\n",
    "    \n",
    "    true=0\n",
    "    false=0\n",
    "    for i in range(0, len(prediction_best)):\n",
    "        if prediction_best[i]==label_num[i]:\n",
    "            true+=1\n",
    "        else:\n",
    "            false+=1\n",
    "            \n",
    "    print(true/(true+false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742065781881131\n",
      "0.8251041046995836\n",
      "0.9811605124340618\n",
      "0.9036568213783404\n",
      "0.8885767790262172\n",
      "0.890748031496063\n",
      "\n",
      "0.815136476426799\n",
      "0.8570736434108527\n",
      "0.8449304174950298\n",
      "0.8185966913861951\n",
      "\n",
      "0.8101127682793743\n"
     ]
    }
   ],
   "source": [
    "predict_acc(m, a)\n",
    "predict_acc(m, p)\n",
    "predict_acc(m, s)\n",
    "predict_acc(a, p)\n",
    "predict_acc(a, s)\n",
    "predict_acc(p, s)\n",
    "print()\n",
    "predict_acc(m, a, p)\n",
    "predict_acc(m, a, s)\n",
    "predict_acc(m, p, s)\n",
    "predict_acc(a, p, s)\n",
    "print()\n",
    "predict_acc(m, a, p, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 WAY LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mscan : 0.5405602037104401\n",
      "apache2 : 0.8177519097853765\n",
      "processtable : 0.7911967988359403\n",
      "snmpguess : 0.5707530010913059\n"
     ]
    }
   ],
   "source": [
    "m=pd.read_csv('data/data_by_label_test_unseen/mscan.csv', 'r', delimiter=',')\n",
    "a=pd.read_csv('data/data_by_label_test_unseen/apache2.csv', 'r', delimiter=',')\n",
    "p=pd.read_csv('data/data_by_label_test_unseen/processtable.csv', 'r', delimiter=',')\n",
    "s=pd.read_csv('data/data_by_label_test_unseen/snmpguess.csv', 'r', delimiter=',')\n",
    "\n",
    "merge=pd.DataFrame(m, columns=m.columns)\n",
    "merge=pd.concat([merge, a], axis=0)\n",
    "merge=pd.concat([merge, p], axis=0)\n",
    "merge=pd.concat([merge, s], axis=0)\n",
    "merge=merge.values\n",
    "\n",
    "feature=[]\n",
    "label=[]\n",
    "for i in merge:\n",
    "    feature.append(i[0:38])\n",
    "    label.append(i[38])\n",
    "feature=np.reshape(feature, (len(feature), 38)).astype(np.float32)\n",
    "\n",
    "support_datas=pd.read_csv('data/support_data/support_data_one_shot.csv', 'r', delimiter=',').values\n",
    "support_data=[]\n",
    "label_array=[]\n",
    "for i in support_datas:\n",
    "    if i[38] in label:\n",
    "        support_data.append(i)\n",
    "        label_array.append(i[38])\n",
    "\n",
    "input1, input2, data_size, support_data_size=make_input(feature, support_data)\n",
    "\n",
    "model=get_siamese_model()\n",
    "model=load_model('model/test1.h5',custom_objects={'initialize_weights':initialize_weights, 'initialize_bias':initialize_bias})\n",
    "prediction=model.predict([input1, input2])\n",
    "prediction=prediction.reshape(data_size, support_data_size)\n",
    "\n",
    "label_num=[]\n",
    "for i in label:\n",
    "    for j in label_array:\n",
    "        if i==j:\n",
    "            label_num.append(label_array.index(i))\n",
    "            \n",
    "\n",
    "for i in range(0, len(prediction[0])):\n",
    "    true=0\n",
    "    false=0\n",
    "    for j in range(0, len(prediction)):\n",
    "        if label_num[j]==i:\n",
    "            if prediction[j][i]<=0.5:\n",
    "                true+=1\n",
    "            else:\n",
    "                false+=1\n",
    "        else:\n",
    "            if prediction[j][i]>0.5:\n",
    "                true+=1\n",
    "            else:\n",
    "                false+=1\n",
    "    print(label_array[i], end=' : ')\n",
    "    print(true/(true+false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
