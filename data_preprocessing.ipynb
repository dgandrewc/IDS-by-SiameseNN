{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMMON DEFINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOMALIZE(TRAIN DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/KDDTrain+.csv', names=['Duration', 'Protocol type', 'Service', 'Flag', 'Source bytes', 'Destination bytes', 'Land', 'Wrong fragment', 'Urgent', 'Hot', 'Number failed logins', 'Logged in', 'Num compromised', 'Root shell', 'Su attempted', 'Num root', 'Num file creations', 'Num shells', 'Num access files', 'Num outbound cmds', 'Is host login', 'Is guest login', 'Count', 'Srv count', 'Serror rate', 'Srv serror rate', 'Rerror rate', 'Srv rerror rate', 'Same srv rate', 'Diff srv rate', 'Srv diff host rate', 'Dst host count', 'Dst host srv count', 'Dst host same srv rate', 'Dst host diff srv rate', 'Dst host same src port rate', 'Dst host srv diff host rate', 'Dst host serror rate', 'Dst host srv serror rate', 'Dst host rerror rate', 'Dst host srv rerro rate', 'Class label'])\n",
    "test=pd.read_csv('data/KDDTest+.csv', names=['Duration', 'Protocol type', 'Service', 'Flag', 'Source bytes', 'Destination bytes', 'Land', 'Wrong fragment', 'Urgent', 'Hot', 'Number failed logins', 'Logged in', 'Num compromised', 'Root shell', 'Su attempted', 'Num root', 'Num file creations', 'Num shells', 'Num access files', 'Num outbound cmds', 'Is host login', 'Is guest login', 'Count', 'Srv count', 'Serror rate', 'Srv serror rate', 'Rerror rate', 'Srv rerror rate', 'Same srv rate', 'Diff srv rate', 'Srv diff host rate', 'Dst host count', 'Dst host srv count', 'Dst host same srv rate', 'Dst host diff srv rate', 'Dst host same src port rate', 'Dst host srv diff host rate', 'Dst host serror rate', 'Dst host srv serror rate', 'Dst host rerror rate', 'Dst host srv rerro rate', 'Class label'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cols_train = train.select_dtypes(include=['float64','int64']).columns\n",
    "cols_test = test.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.transform(test.select_dtypes(include=['float64','int64']))\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols_train)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols_test)\n",
    "sc_traindf = sc_traindf.astype(np.float16)\n",
    "sc_testdf = sc_testdf.astype(np.float16)\n",
    "classtrain=train.select_dtypes(include=['object']).copy()\n",
    "classtest=test.select_dtypes(include=['object']).copy()\n",
    "\n",
    "train_y=classtrain['Class label']\n",
    "train_y=pd.DataFrame(train_y, columns=['Class label'])\n",
    "train=pd.concat([sc_traindf, train_y], axis=1)\n",
    "\n",
    "test_y=classtest['Class label']\n",
    "test_y=pd.DataFrame(test_y, columns=['Class label'])\n",
    "test=pd.concat([sc_testdf, test_y], axis=1)\n",
    "\n",
    "train.to_csv('data/nomalized_train.csv', sep=',', index=False)\n",
    "test=pd.DataFrame(test, columns=train.columns)\n",
    "test.to_csv('data/nomalized_test.csv', sep=',', na_rep='0', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOMALIZE(TEST DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/nomalized_train.csv')\n",
    "test=pd.read_csv('data/nomalized_test.csv')\n",
    "train_index=train['Class label'].value_counts().index\n",
    "test_index=test['Class label'].value_counts().index\n",
    "train_used_label=[]\n",
    "train_unused_data=[]\n",
    "for i in test_index:\n",
    "    if i in train_index:\n",
    "        train_used_label.append(i)\n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    if test.iloc[i].values.tolist()[-1] not in train_used_label:\n",
    "        train_unused_data.append(test.iloc[i].values.tolist())\n",
    "        \n",
    "train_unused_data=pd.DataFrame(train_unused_data, columns=['Duration', 'Source bytes', 'Destination bytes', 'Land', 'Wrong fragment', 'Urgent', 'Hot', 'Number failed logins', 'Logged in', 'Num compromised', 'Root shell', 'Su attempted', 'Num root', 'Num file creations', 'Num shells', 'Num access files', 'Num outbound cmds', 'Is host login', 'Is guest login', 'Count', 'Srv count', 'Serror rate', 'Srv serror rate', 'Rerror rate', 'Srv rerror rate', 'Same srv rate', 'Diff srv rate', 'Srv diff host rate', 'Dst host count', 'Dst host srv count', 'Dst host same srv rate', 'Dst host diff srv rate', 'Dst host same src port rate', 'Dst host srv diff host rate', 'Dst host serror rate', 'Dst host srv serror rate', 'Dst host rerror rate', 'Dst host srv rerro rate', 'Class label'])\n",
    "train_unused_data.to_csv('data/test_unseen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE SUPPORT DATA(FOR ONE SHOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/nomalized_train.csv')\n",
    "test=pd.read_csv('data/nomalized_test.csv')\n",
    "\n",
    "arr=[]\n",
    "support_data=pd.DataFrame(columns=test.columns)\n",
    "for i in range(0, len(train)):\n",
    "    if train.loc[i]['Class label'] not in arr:\n",
    "        arr.append(train.loc[i]['Class label'])\n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    if test.loc[i]['Class label'] not in arr:\n",
    "        arr.append(test.loc[i]['Class label'])\n",
    "        support_data=support_data.append(test.loc[i])\n",
    "support_data.to_csv('data/support_data/support_data_one_shot.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SPLIT BY CLASS LABEL(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/nomalized_train.csv', 'r', encoding='utf-8', delimiter=',')\n",
    "class_label=data.select_dtypes(include=['object']).values\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(class_label)\n",
    "class_label=encoder.transform(class_label)\n",
    "data_by_label=[[] for i in range(0, len(data['Class label'].value_counts()))]\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    data_by_label[class_label[i]].append(data.iloc[i].values.tolist())\n",
    "\n",
    "for i in data_by_label:\n",
    "    i=pd.DataFrame(i, columns=['Duration', 'Source bytes', 'Destination bytes', 'Land', 'Wrong fragment', 'Urgent', 'Hot', 'Number failed logins', 'Logged in', 'Num compromised', 'Root shell', 'Su attempted', 'Num root', 'Num file creations', 'Num shells', 'Num access files', 'Num outbound cmds', 'Is host login', 'Is guest login', 'Count', 'Srv count', 'Serror rate', 'Srv serror rate', 'Rerror rate', 'Srv rerror rate', 'Same srv rate', 'Diff srv rate', 'Srv diff host rate', 'Dst host count', 'Dst host srv count', 'Dst host same srv rate', 'Dst host diff srv rate', 'Dst host same src port rate', 'Dst host srv diff host rate', 'Dst host serror rate', 'Dst host srv serror rate', 'Dst host rerror rate', 'Dst host srv rerro rate', 'Class label'])\n",
    "    i.to_csv('data/data_by_label_train/'+i.iloc[0]['Class label']+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SPLIT BY CLASS LABEL(TEST UNSEEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/test_unseen.csv', 'r', encoding='utf-8', delimiter=',')\n",
    "class_label=data.select_dtypes(include=['object']).values\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(class_label)\n",
    "class_label=encoder.transform(class_label)\n",
    "data_by_label=[[] for i in range(0, len(data['Class label'].value_counts()))]\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    data_by_label[class_label[i]].append(data.iloc[i].values.tolist())\n",
    "\n",
    "for i in data_by_label:\n",
    "    i=pd.DataFrame(i, columns=['Duration', 'Source bytes', 'Destination bytes', 'Land', 'Wrong fragment', 'Urgent', 'Hot', 'Number failed logins', 'Logged in', 'Num compromised', 'Root shell', 'Su attempted', 'Num root', 'Num file creations', 'Num shells', 'Num access files', 'Num outbound cmds', 'Is host login', 'Is guest login', 'Count', 'Srv count', 'Serror rate', 'Srv serror rate', 'Rerror rate', 'Srv rerror rate', 'Same srv rate', 'Diff srv rate', 'Srv diff host rate', 'Dst host count', 'Dst host srv count', 'Dst host same srv rate', 'Dst host diff srv rate', 'Dst host same src port rate', 'Dst host srv diff host rate', 'Dst host serror rate', 'Dst host srv serror rate', 'Dst host rerror rate', 'Dst host srv rerro rate', 'Class label'])\n",
    "    i.to_csv('data/data_by_label_test_unseen/'+i.iloc[0]['Class label']+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=os.listdir('data/data_by_label_train')\n",
    "balanced_data=pd.DataFrame(columns=['Duration', 'Source bytes', 'Destination bytes', 'Land', 'Wrong fragment', 'Urgent', 'Hot', 'Number failed logins', 'Logged in', 'Num compromised', 'Root shell', 'Su attempted', 'Num root', 'Num file creations', 'Num shells', 'Num access files', 'Num outbound cmds', 'Is host login', 'Is guest login', 'Count', 'Srv count', 'Serror rate', 'Srv serror rate', 'Rerror rate', 'Srv rerror rate', 'Same srv rate', 'Diff srv rate', 'Srv diff host rate', 'Dst host count', 'Dst host srv count', 'Dst host same srv rate', 'Dst host diff srv rate', 'Dst host same src port rate', 'Dst host srv diff host rate', 'Dst host serror rate', 'Dst host srv serror rate', 'Dst host rerror rate', 'Dst host srv rerro rate', 'Class label'])\n",
    "for i in file_list:\n",
    "    data=pd.read_csv('data/data_by_label/'+i, 'r', encoding='utf-8', delimiter=',')\n",
    "    while len(data)<60000:\n",
    "        data=pd.concat([data, data], axis=0)\n",
    "    data=data.iloc[0:60000]\n",
    "    data.to_csv('data/balanced_data/'+i, index=False)\n",
    "    balanced_data=balanced_data.append(data)\n",
    "balanced_data=shuffle(balanced_data)\n",
    "balanced_data.to_csv('data/balanced_data/ALL.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE SIAMESE DATA(DIFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/balanced_data/ALL.csv', 'r', encoding='utf-8', delimiter=',')\n",
    "for i in range(0, 16):\n",
    "    input1=data\n",
    "    data=shuffle(data)\n",
    "    input2=data\n",
    "    siamesedatas=[]    \n",
    "    for j in range(0, int(len(data))):\n",
    "        if input1.iloc[j]['Class label']==input2.iloc[j]['Class label']:\n",
    "            leftdata=input1.iloc[j].values[:-1]\n",
    "            rightdata=input2.iloc[j].values[:-1]\n",
    "            siamesedata=np.concatenate((leftdata, rightdata))\n",
    "            siamesedata=np.concatenate((siamesedata, [0]))\n",
    "            siamesedatas.append(siamesedata.tolist())\n",
    "        else:\n",
    "            leftdata=input1.iloc[j].values[:-1]\n",
    "            rightdata=input2.iloc[j].values[:-1]\n",
    "            siamesedata=np.concatenate((leftdata,rightdata))\n",
    "            siamesedata=np.concatenate((siamesedata, [1]))\n",
    "            siamesedatas.append(siamesedata.tolist())\n",
    "    label=pd.DataFrame([1], index=['class'])\n",
    "    siamesedatas=pd.DataFrame(siamesedatas, columns=input1.columns[:-1].append(input1.columns[:-1]).append(label.index))\n",
    "    siamesedatas.to_csv('data/siamese_data_diff/'+str(i)+'.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE SIAMESE DATA(SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=os.listdir('data/balanced_data')\n",
    "for i in range(0, 16):\n",
    "    siamesedatas=[]\n",
    "    for f in file_list:\n",
    "        if f=='ALL.csv':\n",
    "            continue\n",
    "        \n",
    "        data1=pd.read_csv('data/balanced_data/'+f, 'r', encoding='utf-8', delimiter=',')\n",
    "        data2=shuffle(data1)\n",
    "        data2.to_csv('data/balanced_data/'+f, sep=',', index=False)\n",
    "        for j in range(0, int(len(data1))):\n",
    "            leftdata=data1.iloc[j].values[:-1]\n",
    "            rightdata=data2.iloc[j].values[:-1]\n",
    "            siamesedata=np.concatenate((leftdata, rightdata))\n",
    "            siamesedata=np.concatenate((siamesedata, [0]))\n",
    "            siamesedatas.append(siamesedata.tolist())\n",
    "\n",
    "    label=pd.DataFrame([1], index=['class'])\n",
    "    siamesedatas=pd.DataFrame(siamesedatas, columns=data1.columns[:-1].append(data1.columns[:-1]).append(label.index))\n",
    "    siamesedatas.to_csv('data/siamese_data_same/'+str(i)+'.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 16):\n",
    "    same=pd.read_csv('data/siamese_data_same/'+str(i)+'.csv', 'r', encoding='utf-8', delimiter=',')\n",
    "    diff=pd.read_csv('data/siamese_data_diff/'+str(i)+'.csv', 'r', encoding='utf-8', delimiter=',')\n",
    "    siamesedata_merge=pd.concat([same, diff], axis=0)\n",
    "    siamesedata_merge=shuffle(siamesedata_merge)\n",
    "    siamesedata_merge.to_csv('data/siamese_data_merge/'+str(i)+'.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
